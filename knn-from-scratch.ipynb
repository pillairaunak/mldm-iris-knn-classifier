{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f766674-d23c-430b-9c7f-0d33c1562ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and preprocessed successfully.\n",
      "X_train_scaled shape: (120, 4)\n",
      "y_train shape: (120,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.Series(iris.target)\n",
    "\n",
    "# Split data (using the same random_state for a fair comparison)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert labels to NumPy arrays for easier use in our functions\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "print(\"Data loaded and preprocessed successfully.\")\n",
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38adf633-f5d5-44a4-afaa-a5b15be191fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Point A: [-1.72156775 -0.33210111 -1.34572231 -1.32327558]\n",
      "Sample Point B: [-1.12449223 -1.22765467  0.41450518  0.6517626 ]\n",
      "Euclidean Distance between A and B: 2.8562\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculates the Euclidean distance between two points (NumPy arrays).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((point1 - point2)**2))\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Let's test our function with the first two points from the training data.\n",
    "point_a = X_train_scaled[0]\n",
    "point_b = X_train_scaled[1]\n",
    "\n",
    "distance = calculate_distance(point_a, point_b)\n",
    "\n",
    "print(f\"Sample Point A: {point_a}\")\n",
    "print(f\"Sample Point B: {point_b}\")\n",
    "print(f\"Euclidean Distance between A and B: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1670c617-73e1-4e16-a2c3-0b68086c554b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sample: [-1.72156775 -0.10821272 -1.40250384 -1.32327558]\n",
      "Labels of the 5 nearest neighbors: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
      "True label of the test sample: 0\n"
     ]
    }
   ],
   "source": [
    "def get_neighbors(X_train, y_train, test_point, k):\n",
    "    \"\"\"\n",
    "    Finds the k nearest neighbors for a given test point.\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    # Loop through each point in the training set\n",
    "    for index, train_point in enumerate(X_train):\n",
    "        # Calculate the distance\n",
    "        dist = calculate_distance(test_point, train_point)\n",
    "        # Store the distance and the corresponding label\n",
    "        distances.append((dist, y_train[index]))\n",
    "\n",
    "    # Sort the list of distances in ascending order\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Get the top k neighbors\n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(distances[i][1]) # Append only the label\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Let's find the 5 nearest neighbors for the first point in our test set\n",
    "k = 5\n",
    "test_sample = X_test_scaled[0]\n",
    "\n",
    "neighbor_labels = get_neighbors(X_train_scaled, y_train, test_sample, k)\n",
    "\n",
    "print(f\"Test Sample: {test_sample}\")\n",
    "print(f\"Labels of the {k} nearest neighbors: {neighbor_labels}\")\n",
    "print(f\"True label of the test sample: {y_test[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f69cda2-ee30-4901-bfeb-e4261ee5c9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor labels: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
      "Final Prediction: 0\n",
      "True Label: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def predict(neighbors):\n",
    "    \"\"\"\n",
    "    Makes a prediction based on a majority vote of neighbors.\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each label\n",
    "    vote_counts = Counter(neighbors)\n",
    "    \n",
    "    # Find the most common label and return it\n",
    "    # .most_common(1) returns a list of the most common items and their counts\n",
    "    # e.g., [(1, 4)] which means label 1 appeared 4 times.\n",
    "    # We take the first element of the list [0], and then the label from that tuple [0].\n",
    "    prediction = vote_counts.most_common(1)[0][0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Let's use the neighbor_labels we found in the previous step\n",
    "print(f\"Neighbor labels: {neighbor_labels}\")\n",
    "\n",
    "final_prediction = predict(neighbor_labels)\n",
    "print(f\"Final Prediction: {final_prediction}\")\n",
    "print(f\"True Label: {y_test[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7176e726-619f-4ef5-89af-87994ce61d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- From-Scratch k-NN Model ---\n",
      "Accuracy: 0.9333\n",
      "\n",
      "--- Scikit-learn k-NN Benchmark ---\n",
      "Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# A list to store our predictions\n",
    "predictions = []\n",
    "k = 5 # Use the same k as our scikit-learn model\n",
    "\n",
    "# Loop through each sample in the test set\n",
    "for test_point in X_test_scaled:\n",
    "    # 1. Find the neighbors for the current test point\n",
    "    neighbor_labels = get_neighbors(X_train_scaled, y_train, test_point, k)\n",
    "    \n",
    "    # 2. Make a prediction based on the neighbors\n",
    "    final_prediction = predict(neighbor_labels)\n",
    "    \n",
    "    # 3. Add the prediction to our list\n",
    "    predictions.append(final_prediction)\n",
    "\n",
    "# Calculate the accuracy by comparing our predictions to the true labels\n",
    "# We sum up the cases where the prediction was correct and divide by the total number of test samples.\n",
    "accuracy = np.sum(predictions == y_test) / len(y_test)\n",
    "\n",
    "print(f\"--- From-Scratch k-NN Model ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\n--- Scikit-learn k-NN Benchmark ---\")\n",
    "print(f\"Accuracy: 0.9333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67502923-1898-40df-a3e4-b324d5e5f7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
